{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d733e7d1-a7c8-4b80-aed8-80cec2fbf243",
   "metadata": {},
   "source": [
    "# **Advanced Model**\n",
    "- Best model with **< 0.05** P-values, **low** condition number, and **underfits**\n",
    "- Features included:\n",
    "    * **`Year`**\n",
    "    * **`Infant_deaths`**\n",
    "    * **`Under_five_deaths`**\n",
    "    * **`Adult_mortality`**\n",
    "    * **`BMI`**\n",
    "    * **`Incidents_HIV`**\n",
    "    * **`GDP_per_capita`**\n",
    "    * **`Schooling`**\n",
    "    * **`Econonmy_status_Developed`**\n",
    "    * All 8 **`Region`** (one-hot-encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6043258-7977-42ee-a1f7-6176147822ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tools\n",
    "import joblib\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777cbe90-e737-4e77-af8d-5f7debe124a5",
   "metadata": {},
   "source": [
    "## **Train-Test-Split**\n",
    "- `Life Expectancy Data.csv` was read into a pandas dataframe.\n",
    "- The features and target for modelling and predicting were separated.\n",
    "- Dataset was split into an **80-20** split using a `random_state` of 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e912e31f-ca81-442a-9e17-1b9d2d5086ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHO = pd.read_csv(\"Life Expectancy Data.csv\")   # Reading the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323b492c-4c22-40a5-b87f-b5c1ee0fde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing for Train-test splitting\n",
    "\n",
    "feature_cols = list(WHO.columns)        # Extracts the columns and creates a list out of it\n",
    "feature_cols.remove('Life_expectancy')  # Removes the 'life expectancy' column to make it the features for the X_train and the X_test\n",
    "\n",
    "X = WHO[feature_cols]       # Creates the features to learn from\n",
    "y = WHO['Life_expectancy']  # Separates the 'life_expectancy' as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd2e79e-b851-4b42-964d-8fac34a1e9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country',\n",
       " 'Region',\n",
       " 'Year',\n",
       " 'Infant_deaths',\n",
       " 'Under_five_deaths',\n",
       " 'Adult_mortality',\n",
       " 'Alcohol_consumption',\n",
       " 'Hepatitis_B',\n",
       " 'Measles',\n",
       " 'BMI',\n",
       " 'Polio',\n",
       " 'Diphtheria',\n",
       " 'Incidents_HIV',\n",
       " 'GDP_per_capita',\n",
       " 'Population_mln',\n",
       " 'Thinness_ten_nineteen_years',\n",
       " 'Thinness_five_nine_years',\n",
       " 'Schooling',\n",
       " 'Economy_status_Developed',\n",
       " 'Economy_status_Developing']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols # Check that the 'life_expectancy' column has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702c61fd-1f01-4e6c-bac6-f6a1526f3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,                  # The features\n",
    "                                                    y,                  # The target\n",
    "                                                    test_size = 0.2,    # Allocated 20% of the data to test\n",
    "                                                    random_state = 23)  # Add a random state\n",
    "# 80-20 train-test split with a random state value of 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a3998-e6cd-4a25-ae77-4b7a99bc0375",
   "metadata": {},
   "source": [
    "## **Feature Engineering**\n",
    "- A **`feature_eng`** function was created that had 4 arguements:\n",
    "    - **`train_df`** represents the training dataset\n",
    "    - **`test_df`** represents the test dataset or user input\n",
    "    - **`save_metadata`** represents whether to save the scaler and feature columns. **Only** set as **`True`** during training\n",
    "    - **`include_regions`** represents whether to include the regions or not. **Only** include when using the **Advanced Model**\n",
    "- The function returns:\n",
    "    - **`train_df`** represents feature engineered train dataset\n",
    "    -  **`test_df`** represents feature engineered test dataset\n",
    "- During training when **`save_metadata`** is `True` the scaler and feature columns from the train phase are saved using [joblib module](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html) and loaded up in the predict phase to ensure the test dataset is scaled with the train dataset, avoiding **data leakage**.\n",
    "- **`feature_columns`** is used to align the train and test/input dataset together.\n",
    "- The saved **`scaler`** is used to scale the test/input dataset.\n",
    "- The **`constant`** are added at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5ed04c-28b1-4fa8-ab20-b102b744cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING FUNCTION\n",
    "\n",
    "def feature_eng(train_df, test_df, save_metadata=True, include_regions=True):\n",
    "    \"\"\"\n",
    "    Feature engineering function with joblib for saving/loading scalers and feature columns.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training dataset.\n",
    "        test_df (pd.DataFrame): Test dataset or user input.\n",
    "        save_metadata (bool): Whether to save the scaler and feature columns. Only set to True during training.\n",
    "        include_regions (bool): Whether to include the regions or not. Only include if using the advanced model\n",
    "    Returns:\n",
    "        train_df (pd.DataFrame): training dataset.\n",
    "        test_df (pd.DataFrame): test dataset.\n",
    "    \"\"\"\n",
    "    train_df = train_df.copy()  # Copy the training dataset\n",
    "    test_df = test_df.copy()  # Copy the test dataset\n",
    "\n",
    "    # All columns that needs to be scaled\n",
    "    scale_columns = ['Year', 'Infant_deaths', 'Under_five_deaths', 'Adult_mortality',\n",
    "                     'Alcohol_consumption', 'Hepatitis_B', 'Measles', 'BMI',\n",
    "                     'Polio', 'Diphtheria', 'Incidents_HIV', 'GDP_per_capita',\n",
    "                     'Population_mln', 'Thinness_ten_nineteen_years',\n",
    "                     'Thinness_five_nine_years', 'Schooling']\n",
    "\n",
    "    # Training phase:\n",
    "    if save_metadata:\n",
    "        # Fit scaler and save feature columns\n",
    "        train_df = pd.get_dummies(train_df, columns=['Region'], drop_first=True, prefix='Region', dtype=int) # OHE the regions\n",
    "\n",
    "        # Fit scaler and extract the train columns\n",
    "        scaler = StandardScaler()                                                 # Call the scaling method\n",
    "        train_df[scale_columns] = scaler.fit_transform(train_df[scale_columns])   # Fit scaler and transform the training dataset\n",
    "        feature_columns = train_df.columns                                        # Extract the training columns\n",
    "\n",
    "        # Save scaler and feature columns\n",
    "        joblib.dump(scaler, 'scaler')                   # Save the training scaler\n",
    "        joblib.dump(feature_columns, 'feature_columns') # Save the feature columns\n",
    "\n",
    "    # Prediction phase:\n",
    "    else:\n",
    "        # Load scaler and feature columns\n",
    "        scaler = joblib.load('scaler')                    # Load the training scaler\n",
    "        feature_columns = joblib.load('feature_columns')  # Load the feature columns\n",
    "\n",
    "        # If Region is present in test dataset:\n",
    "        if include_regions and 'Region' in test_df.columns:\n",
    "            test_df = pd.get_dummies(test_df, columns=['Region'], drop_first=False, prefix='Region', dtype=int) # OHE the regions and keep the first column\n",
    "\n",
    "        # If region is not present in the test dataset\n",
    "        else:\n",
    "            test_df.drop(columns=['Region'], errors='ignore', inplace=True) # Drop the regions columns\n",
    "\n",
    "        # Align test_df with train_df before scaling\n",
    "        test_df = test_df.reindex(columns=feature_columns, fill_value=0)          # aligns the test and train dataset together and fills the missing values with 0\n",
    "        common_columns = [col for col in scale_columns if col in test_df.columns] # Find the common columns from the scale_columns and the test dataset\n",
    "        test_df[common_columns] = scaler.transform(test_df[common_columns])       # Scales the test dataset on the common columns using the training scaler\n",
    "\n",
    "    # Add Constant\n",
    "    train_df = sm.add_constant(train_df, has_constant='add') # Add constant to the training dataset\n",
    "    test_df = sm.add_constant(test_df, has_constant='add')   # Add constant to the testing dataset\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c914e41a-7490-4a5b-9a76-3e1539910bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fe, X_test_fe = feature_eng(X_train, X_test) # Feature engineering the train and test dataset for the fitting of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a7a0fc-349f-465d-b488-2856436ae25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Infant_deaths</th>\n",
       "      <th>Under_five_deaths</th>\n",
       "      <th>Adult_mortality</th>\n",
       "      <th>Alcohol_consumption</th>\n",
       "      <th>Hepatitis_B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>...</th>\n",
       "      <th>Economy_status_Developed</th>\n",
       "      <th>Economy_status_Developing</th>\n",
       "      <th>Region_Asia</th>\n",
       "      <th>Region_Central America and Caribbean</th>\n",
       "      <th>Region_European Union</th>\n",
       "      <th>Region_Middle East</th>\n",
       "      <th>Region_North America</th>\n",
       "      <th>Region_Oceania</th>\n",
       "      <th>Region_Rest of Europe</th>\n",
       "      <th>Region_South America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>0.952270</td>\n",
       "      <td>-1.028415</td>\n",
       "      <td>-0.907783</td>\n",
       "      <td>-1.196121</td>\n",
       "      <td>-0.723955</td>\n",
       "      <td>0.799286</td>\n",
       "      <td>0.950472</td>\n",
       "      <td>-0.644257</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>0.515765</td>\n",
       "      <td>0.541674</td>\n",
       "      <td>0.352960</td>\n",
       "      <td>0.370161</td>\n",
       "      <td>-1.200723</td>\n",
       "      <td>-0.529570</td>\n",
       "      <td>0.950472</td>\n",
       "      <td>-0.780855</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Austria</td>\n",
       "      <td>-1.012001</td>\n",
       "      <td>-0.952267</td>\n",
       "      <td>-0.853751</td>\n",
       "      <td>-0.913923</td>\n",
       "      <td>1.905876</td>\n",
       "      <td>-0.086618</td>\n",
       "      <td>-1.656268</td>\n",
       "      <td>0.038736</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lesotho</td>\n",
       "      <td>-1.448505</td>\n",
       "      <td>1.448192</td>\n",
       "      <td>1.478623</td>\n",
       "      <td>3.597649</td>\n",
       "      <td>-0.493179</td>\n",
       "      <td>-0.339734</td>\n",
       "      <td>-1.656268</td>\n",
       "      <td>-0.416593</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>-0.793748</td>\n",
       "      <td>0.683091</td>\n",
       "      <td>0.778461</td>\n",
       "      <td>2.690922</td>\n",
       "      <td>0.609981</td>\n",
       "      <td>-0.529570</td>\n",
       "      <td>-1.390274</td>\n",
       "      <td>0.676195</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>0.952270</td>\n",
       "      <td>0.063033</td>\n",
       "      <td>-0.122070</td>\n",
       "      <td>-0.052038</td>\n",
       "      <td>-0.576867</td>\n",
       "      <td>0.103218</td>\n",
       "      <td>-1.922262</td>\n",
       "      <td>-1.463847</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Norway</td>\n",
       "      <td>-0.138992</td>\n",
       "      <td>-0.999406</td>\n",
       "      <td>-0.887521</td>\n",
       "      <td>-1.093126</td>\n",
       "      <td>0.457821</td>\n",
       "      <td>0.229776</td>\n",
       "      <td>0.844075</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Czechia</td>\n",
       "      <td>-1.012001</td>\n",
       "      <td>-0.966771</td>\n",
       "      <td>-0.862756</td>\n",
       "      <td>-0.630140</td>\n",
       "      <td>2.301492</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>1.110069</td>\n",
       "      <td>0.721728</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>0.079261</td>\n",
       "      <td>-0.908754</td>\n",
       "      <td>-0.824484</td>\n",
       "      <td>-0.225231</td>\n",
       "      <td>1.763860</td>\n",
       "      <td>0.229776</td>\n",
       "      <td>1.163268</td>\n",
       "      <td>0.721728</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.297513</td>\n",
       "      <td>-0.876120</td>\n",
       "      <td>-0.801971</td>\n",
       "      <td>-0.745311</td>\n",
       "      <td>0.982773</td>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.471683</td>\n",
       "      <td>1.541319</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2291 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      const        Country      Year  Infant_deaths  Under_five_deaths  \\\n",
       "2676    1.0      Singapore  0.952270      -1.028415          -0.907783   \n",
       "369     1.0    Yemen, Rep.  0.515765       0.541674           0.352960   \n",
       "466     1.0        Austria -1.012001      -0.952267          -0.853751   \n",
       "1739    1.0        Lesotho -1.448505       1.448192           1.478623   \n",
       "649     1.0   South Africa -0.793748       0.683091           0.778461   \n",
       "...     ...            ...       ...            ...                ...   \n",
       "1512    1.0       Cambodia  0.952270       0.063033          -0.122070   \n",
       "1993    1.0         Norway -0.138992      -0.999406          -0.887521   \n",
       "1064    1.0        Czechia -1.012001      -0.966771          -0.862756   \n",
       "742     1.0        Hungary  0.079261      -0.908754          -0.824484   \n",
       "595     1.0  United States  0.297513      -0.876120          -0.801971   \n",
       "\n",
       "      Adult_mortality  Alcohol_consumption  Hepatitis_B   Measles       BMI  \\\n",
       "2676        -1.196121            -0.723955     0.799286  0.950472 -0.644257   \n",
       "369          0.370161            -1.200723    -0.529570  0.950472 -0.780855   \n",
       "466         -0.913923             1.905876    -0.086618 -1.656268  0.038736   \n",
       "1739         3.597649            -0.493179    -0.339734 -1.656268 -0.416593   \n",
       "649          2.690922             0.609981    -0.529570 -1.390274  0.676195   \n",
       "...               ...                  ...          ...       ...       ...   \n",
       "1512        -0.052038            -0.576867     0.103218 -1.922262 -1.463847   \n",
       "1993        -1.093126             0.457821     0.229776  0.844075  0.539597   \n",
       "1064        -0.630140             2.301492     0.482891  1.110069  0.721728   \n",
       "742         -0.225231             1.763860     0.229776  1.163268  0.721728   \n",
       "595         -0.745311             0.982773     0.482891  0.471683  1.541319   \n",
       "\n",
       "      ...  Economy_status_Developed  Economy_status_Developing  Region_Asia  \\\n",
       "2676  ...                         0                          1            1   \n",
       "369   ...                         0                          1            0   \n",
       "466   ...                         1                          0            0   \n",
       "1739  ...                         0                          1            0   \n",
       "649   ...                         0                          1            0   \n",
       "...   ...                       ...                        ...          ...   \n",
       "1512  ...                         0                          1            1   \n",
       "1993  ...                         1                          0            0   \n",
       "1064  ...                         1                          0            0   \n",
       "742   ...                         1                          0            0   \n",
       "595   ...                         1                          0            0   \n",
       "\n",
       "      Region_Central America and Caribbean  Region_European Union  \\\n",
       "2676                                     0                      0   \n",
       "369                                      0                      0   \n",
       "466                                      0                      1   \n",
       "1739                                     0                      0   \n",
       "649                                      0                      0   \n",
       "...                                    ...                    ...   \n",
       "1512                                     0                      0   \n",
       "1993                                     0                      0   \n",
       "1064                                     0                      1   \n",
       "742                                      0                      1   \n",
       "595                                      0                      0   \n",
       "\n",
       "      Region_Middle East  Region_North America  Region_Oceania  \\\n",
       "2676                   0                     0               0   \n",
       "369                    1                     0               0   \n",
       "466                    0                     0               0   \n",
       "1739                   0                     0               0   \n",
       "649                    0                     0               0   \n",
       "...                  ...                   ...             ...   \n",
       "1512                   0                     0               0   \n",
       "1993                   0                     0               0   \n",
       "1064                   0                     0               0   \n",
       "742                    0                     0               0   \n",
       "595                    0                     1               0   \n",
       "\n",
       "      Region_Rest of Europe  Region_South America  \n",
       "2676                      0                     0  \n",
       "369                       0                     0  \n",
       "466                       0                     0  \n",
       "1739                      0                     0  \n",
       "649                       0                     0  \n",
       "...                     ...                   ...  \n",
       "1512                      0                     0  \n",
       "1993                      1                     0  \n",
       "1064                      0                     0  \n",
       "742                       0                     0  \n",
       "595                       0                     0  \n",
       "\n",
       "[2291 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fe # Check of feature engineered dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347cdbba-cdba-4ddc-a364-ecee74002c95",
   "metadata": {},
   "source": [
    "## **Modelling**\n",
    "- Specific columns are removed before the model was trained such as:\n",
    "    - **`Economy_status_Developing`** which had high correlation to **`Economy_status_Developed`**.\n",
    "    - **`Country`** which would introduce a large amount of bias to the model.\n",
    "- Linear Regression model was created using the **Ordinary Least Squares** method\n",
    "- The model was fitted.\n",
    "- The model results are saved using the statsmodels [.save()](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.save.html) method.\n",
    "- Summary was generated giving:\n",
    "    - **`R_squared`** value of **0.984**\n",
    "    - **`Cond No`** value of **27.7**\n",
    "    - **`P-Value`** of all features **< 0.05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec422659-63c9-41e5-b48c-28e266169f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING COLUMNS BEFORE MODELLING\n",
    "\n",
    "# Define a set of columns to be removed\n",
    "cols_to_remove = {'Country', 'Alcohol_consumption', 'Economy_status_Developing',\n",
    "                  'Polio', 'Diphtheria', 'Population_mln', 'Thinness_five_nine_years',\n",
    "                  'Thinness_ten_nineteen_years', 'Measles', 'Hepatitis_B'}\n",
    "\n",
    "# Create a list of feature columns by excluding the ones listed in cols_to_remove from the columns in X_train_fe\n",
    "feature_cols = [col for col in list(X_train_fe.columns) if col not in cols_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0bbd762-9b02-4489-ad19-4dc5c9196148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Life_expectancy</td> <th>  R-squared:         </th> <td>   0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8096.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 09 Dec 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:49:36</td>     <th>  Log-Likelihood:    </th> <td> -3663.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2291</td>      <th>  AIC:               </th> <td>   7362.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2273</td>      <th>  BIC:               </th> <td>   7465.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                    <td></td>                      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                <td>   67.9636</td> <td>    0.074</td> <td>  913.119</td> <td> 0.000</td> <td>   67.818</td> <td>   68.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Year</th>                                 <td>    0.1449</td> <td>    0.027</td> <td>    5.435</td> <td> 0.000</td> <td>    0.093</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Infant_deaths</th>                        <td>   -1.5101</td> <td>    0.172</td> <td>   -8.770</td> <td> 0.000</td> <td>   -1.848</td> <td>   -1.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Under_five_deaths</th>                    <td>   -2.1271</td> <td>    0.174</td> <td>  -12.200</td> <td> 0.000</td> <td>   -2.469</td> <td>   -1.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Adult_mortality</th>                      <td>   -5.2894</td> <td>    0.070</td> <td>  -75.636</td> <td> 0.000</td> <td>   -5.427</td> <td>   -5.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>                                  <td>   -0.2774</td> <td>    0.047</td> <td>   -5.898</td> <td> 0.000</td> <td>   -0.370</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Incidents_HIV</th>                        <td>    0.1604</td> <td>    0.043</td> <td>    3.711</td> <td> 0.000</td> <td>    0.076</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GDP_per_capita</th>                       <td>    0.3755</td> <td>    0.041</td> <td>    9.251</td> <td> 0.000</td> <td>    0.296</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Schooling</th>                            <td>    0.3703</td> <td>    0.056</td> <td>    6.618</td> <td> 0.000</td> <td>    0.261</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Economy_status_Developed</th>             <td>    2.5140</td> <td>    0.165</td> <td>   15.232</td> <td> 0.000</td> <td>    2.190</td> <td>    2.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_Asia</th>                          <td>    0.4416</td> <td>    0.107</td> <td>    4.127</td> <td> 0.000</td> <td>    0.232</td> <td>    0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_Central America and Caribbean</th> <td>    2.0889</td> <td>    0.118</td> <td>   17.734</td> <td> 0.000</td> <td>    1.858</td> <td>    2.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_European Union</th>                <td>   -0.5946</td> <td>    0.175</td> <td>   -3.397</td> <td> 0.001</td> <td>   -0.938</td> <td>   -0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_Middle East</th>                   <td>    0.3759</td> <td>    0.135</td> <td>    2.787</td> <td> 0.005</td> <td>    0.111</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_North America</th>                 <td>    0.5927</td> <td>    0.246</td> <td>    2.409</td> <td> 0.016</td> <td>    0.110</td> <td>    1.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_Oceania</th>                       <td>   -0.6965</td> <td>    0.142</td> <td>   -4.915</td> <td> 0.000</td> <td>   -0.974</td> <td>   -0.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_Rest of Europe</th>                <td>    0.3624</td> <td>    0.137</td> <td>    2.653</td> <td> 0.008</td> <td>    0.094</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_South America</th>                 <td>    1.8119</td> <td>    0.133</td> <td>   13.596</td> <td> 0.000</td> <td>    1.551</td> <td>    2.073</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.211</td> <th>  Durbin-Watson:     </th> <td>   2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.027</td> <th>  Jarque-Bera (JB):  </th> <td>   7.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.108</td> <th>  Prob(JB):          </th> <td>  0.0250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.175</td> <th>  Cond. No.          </th> <td>    27.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                        & Life\\_expectancy & \\textbf{  R-squared:         } &     0.984   \\\\\n",
       "\\textbf{Model:}                                &       OLS        & \\textbf{  Adj. R-squared:    } &     0.984   \\\\\n",
       "\\textbf{Method:}                               &  Least Squares   & \\textbf{  F-statistic:       } &     8096.   \\\\\n",
       "\\textbf{Date:}                                 & Mon, 09 Dec 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                                 &     15:49:36     & \\textbf{  Log-Likelihood:    } &   -3663.1   \\\\\n",
       "\\textbf{No. Observations:}                     &        2291      & \\textbf{  AIC:               } &     7362.   \\\\\n",
       "\\textbf{Df Residuals:}                         &        2273      & \\textbf{  BIC:               } &     7465.   \\\\\n",
       "\\textbf{Df Model:}                             &          17      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                      &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                                 &      67.9636  &        0.074     &   913.119  &         0.000        &       67.818    &       68.110     \\\\\n",
       "\\textbf{Year}                                  &       0.1449  &        0.027     &     5.435  &         0.000        &        0.093    &        0.197     \\\\\n",
       "\\textbf{Infant\\_deaths}                        &      -1.5101  &        0.172     &    -8.770  &         0.000        &       -1.848    &       -1.172     \\\\\n",
       "\\textbf{Under\\_five\\_deaths}                   &      -2.1271  &        0.174     &   -12.200  &         0.000        &       -2.469    &       -1.785     \\\\\n",
       "\\textbf{Adult\\_mortality}                      &      -5.2894  &        0.070     &   -75.636  &         0.000        &       -5.427    &       -5.152     \\\\\n",
       "\\textbf{BMI}                                   &      -0.2774  &        0.047     &    -5.898  &         0.000        &       -0.370    &       -0.185     \\\\\n",
       "\\textbf{Incidents\\_HIV}                        &       0.1604  &        0.043     &     3.711  &         0.000        &        0.076    &        0.245     \\\\\n",
       "\\textbf{GDP\\_per\\_capita}                      &       0.3755  &        0.041     &     9.251  &         0.000        &        0.296    &        0.455     \\\\\n",
       "\\textbf{Schooling}                             &       0.3703  &        0.056     &     6.618  &         0.000        &        0.261    &        0.480     \\\\\n",
       "\\textbf{Economy\\_status\\_Developed}            &       2.5140  &        0.165     &    15.232  &         0.000        &        2.190    &        2.838     \\\\\n",
       "\\textbf{Region\\_Asia}                          &       0.4416  &        0.107     &     4.127  &         0.000        &        0.232    &        0.651     \\\\\n",
       "\\textbf{Region\\_Central America and Caribbean} &       2.0889  &        0.118     &    17.734  &         0.000        &        1.858    &        2.320     \\\\\n",
       "\\textbf{Region\\_European Union}                &      -0.5946  &        0.175     &    -3.397  &         0.001        &       -0.938    &       -0.251     \\\\\n",
       "\\textbf{Region\\_Middle East}                   &       0.3759  &        0.135     &     2.787  &         0.005        &        0.111    &        0.640     \\\\\n",
       "\\textbf{Region\\_North America}                 &       0.5927  &        0.246     &     2.409  &         0.016        &        0.110    &        1.075     \\\\\n",
       "\\textbf{Region\\_Oceania}                       &      -0.6965  &        0.142     &    -4.915  &         0.000        &       -0.974    &       -0.419     \\\\\n",
       "\\textbf{Region\\_Rest of Europe}                &       0.3624  &        0.137     &     2.653  &         0.008        &        0.094    &        0.630     \\\\\n",
       "\\textbf{Region\\_South America}                 &       1.8119  &        0.133     &    13.596  &         0.000        &        1.551    &        2.073     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  7.211 & \\textbf{  Durbin-Watson:     } &    2.048  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.027 & \\textbf{  Jarque-Bera (JB):  } &    7.381  \\\\\n",
       "\\textbf{Skew:}          &  0.108 & \\textbf{  Prob(JB):          } &   0.0250  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.175 & \\textbf{  Cond. No.          } &     27.7  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        Life_expectancy   R-squared:                       0.984\n",
       "Model:                            OLS   Adj. R-squared:                  0.984\n",
       "Method:                 Least Squares   F-statistic:                     8096.\n",
       "Date:                Mon, 09 Dec 2024   Prob (F-statistic):               0.00\n",
       "Time:                        15:49:36   Log-Likelihood:                -3663.1\n",
       "No. Observations:                2291   AIC:                             7362.\n",
       "Df Residuals:                    2273   BIC:                             7465.\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================================\n",
       "                                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------\n",
       "const                                   67.9636      0.074    913.119      0.000      67.818      68.110\n",
       "Year                                     0.1449      0.027      5.435      0.000       0.093       0.197\n",
       "Infant_deaths                           -1.5101      0.172     -8.770      0.000      -1.848      -1.172\n",
       "Under_five_deaths                       -2.1271      0.174    -12.200      0.000      -2.469      -1.785\n",
       "Adult_mortality                         -5.2894      0.070    -75.636      0.000      -5.427      -5.152\n",
       "BMI                                     -0.2774      0.047     -5.898      0.000      -0.370      -0.185\n",
       "Incidents_HIV                            0.1604      0.043      3.711      0.000       0.076       0.245\n",
       "GDP_per_capita                           0.3755      0.041      9.251      0.000       0.296       0.455\n",
       "Schooling                                0.3703      0.056      6.618      0.000       0.261       0.480\n",
       "Economy_status_Developed                 2.5140      0.165     15.232      0.000       2.190       2.838\n",
       "Region_Asia                              0.4416      0.107      4.127      0.000       0.232       0.651\n",
       "Region_Central America and Caribbean     2.0889      0.118     17.734      0.000       1.858       2.320\n",
       "Region_European Union                   -0.5946      0.175     -3.397      0.001      -0.938      -0.251\n",
       "Region_Middle East                       0.3759      0.135      2.787      0.005       0.111       0.640\n",
       "Region_North America                     0.5927      0.246      2.409      0.016       0.110       1.075\n",
       "Region_Oceania                          -0.6965      0.142     -4.915      0.000      -0.974      -0.419\n",
       "Region_Rest of Europe                    0.3624      0.137      2.653      0.008       0.094       0.630\n",
       "Region_South America                     1.8119      0.133     13.596      0.000       1.551       2.073\n",
       "==============================================================================\n",
       "Omnibus:                        7.211   Durbin-Watson:                   2.048\n",
       "Prob(Omnibus):                  0.027   Jarque-Bera (JB):                7.381\n",
       "Skew:                           0.108   Prob(JB):                       0.0250\n",
       "Kurtosis:                       3.175   Cond. No.                         27.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = sm.OLS(y_train, X_train_fe[feature_cols]) # Create a linear regression model using the Ordinary Least Squares method.\n",
    "results = lin_reg.fit()                             # Fit the OLS model to the training data\n",
    "results.save('advanced_model')                      # Save the trained model to a file ('advanced_model')\n",
    "results.summary()                                   # Generate and display a summary of the fitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1eb1e-9f2f-4601-bcea-2c0b2f6958df",
   "metadata": {},
   "source": [
    "## **Test & Metrics**\n",
    "- **RMSE** was calculated on the training prediction giving a value of **1.197** which means the prediction was on average 1.197 years off the true value.\n",
    "- **MAPE** was also calculated to give the average error as a percentage of the actual life expectancy for the train prediction giving a value of **1.45%**.\n",
    "- The **`feature_eng`** function was run again for the prediction phase on the train and test/input dataset.\n",
    "- **RMSE** was calculated on the testing prediction giving a value of **1.205** which means the prediction was on average 1.205 years off the true value.\n",
    "- **MAPE** was also calculated to give the average error as a percentage of the actual life expectancy for the test prediction giving a value of **1.476%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58a3ccd9-c2f5-46f8-a2ba-d8e63e7957ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1971726790615589\n"
     ]
    }
   ],
   "source": [
    "## Let's check the performance of our model\n",
    "\n",
    "y_pred = results.predict(X_train_fe[feature_cols])           # Use the trained regression model to make predictions on the training dataset.\n",
    "rmse = statsmodels.tools.eval_measures.rmse(y_train, y_pred) # Calculate the Root Mean Squared Error (RMSE) between the actual target values (y_train) and the predicted values (y_pred)\n",
    "print(rmse)                                                  # Prints the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a68473db-7729-4691-9cc7-5f320e766f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4510375442285888%\n"
     ]
    }
   ],
   "source": [
    "mape = metrics.mean_absolute_percentage_error(y_train,y_pred) # Calculate the MAPE\n",
    "print(f\"{mape*100}%\")                                         # Print the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b543ce2-5104-4695-adf5-cfe232612169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING FUNCTION\n",
    "\n",
    "def feature_eng(train_df, test_df, save_metadata=False, include_regions=True):\n",
    "    \"\"\"\n",
    "    Feature engineering function with joblib for saving/loading scalers and feature columns.\n",
    "    \n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training dataset.\n",
    "        test_df (pd.DataFrame): Test dataset or user input.\n",
    "        save_metadata (bool): Whether to save the scaler and feature columns. Only set to True during training.\n",
    "        include_regions (bool): Whether to include the regions or not. Only include if using the advanced model\n",
    "    Returns:\n",
    "        train_df (pd.DataFrame): training dataset.\n",
    "        test_df (pd.DataFrame): test dataset.\n",
    "    \"\"\"\n",
    "    train_df = train_df.copy()  # Copy the training dataset\n",
    "    test_df = test_df.copy()  # Copy the test dataset\n",
    "\n",
    "    # All columns that needs to be scaled\n",
    "    scale_columns = ['Year', 'Infant_deaths', 'Under_five_deaths', 'Adult_mortality',\n",
    "                     'Alcohol_consumption', 'Hepatitis_B', 'Measles', 'BMI',\n",
    "                     'Polio', 'Diphtheria', 'Incidents_HIV', 'GDP_per_capita',\n",
    "                     'Population_mln', 'Thinness_ten_nineteen_years',\n",
    "                     'Thinness_five_nine_years', 'Schooling']\n",
    "\n",
    "    # Training phase:\n",
    "    if save_metadata:\n",
    "        # Fit scaler and save feature columns\n",
    "        train_df = pd.get_dummies(train_df, columns=['Region'], drop_first=True, prefix='Region', dtype=int) # OHE the regions\n",
    "\n",
    "        # Fit scaler and extract the train columns\n",
    "        scaler = StandardScaler()                                                 # Call the scaling method\n",
    "        train_df[scale_columns] = scaler.fit_transform(train_df[scale_columns])   # Fit scaler and transform the training dataset\n",
    "        feature_columns = train_df.columns                                        # Extract the training columns\n",
    "\n",
    "        # Save scaler and feature columns\n",
    "        joblib.dump(scaler, 'scaler')                   # Save the training scaler\n",
    "        joblib.dump(feature_columns, 'feature_columns') # Save the feature columns\n",
    "\n",
    "    # Prediction phase:\n",
    "    else:\n",
    "        # Load scaler and feature columns\n",
    "        scaler = joblib.load('scaler')                    # Load the training scaler\n",
    "        feature_columns = joblib.load('feature_columns')  # Load the feature columns\n",
    "\n",
    "        # If Region is present in test dataset:\n",
    "        if include_regions and 'Region' in test_df.columns:\n",
    "            test_df = pd.get_dummies(test_df, columns=['Region'], drop_first=False, prefix='Region', dtype=int) # OHE the regions and keep the first column\n",
    "\n",
    "        # If region is not present in the test dataset\n",
    "        else:\n",
    "            test_df.drop(columns=['Region'], errors='ignore', inplace=True) # Drop the regions columns\n",
    "\n",
    "        # Align test_df with train_df before scaling\n",
    "        test_df = test_df.reindex(columns=feature_columns, fill_value=0)          # aligns the test and train dataset together and fills the missing values with 0\n",
    "        common_columns = [col for col in scale_columns if col in test_df.columns] # Find the common columns from the scale_columns and the test dataset\n",
    "        test_df[common_columns] = scaler.transform(test_df[common_columns])       # Scales the test dataset on the common columns using the training scaler\n",
    "\n",
    "    # Add Constant\n",
    "    train_df = sm.add_constant(train_df, has_constant='add') # Add constant to the training dataset\n",
    "    test_df = sm.add_constant(test_df, has_constant='add')   # Add constant to the testing dataset\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed6ac1bb-1e25-4a7d-977c-6679b0c67a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_test_fe = feature_eng(X_train, X_test) # Feature engineering the test dataset for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2c666cf-5b42-4c71-9f35-4cca084b21c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2054852329139532\n"
     ]
    }
   ],
   "source": [
    "# This is\n",
    "y_test_pred = results.predict(X_test_fe[feature_cols])           # Use the trained regression model to make predictions on the test dataset.\n",
    "rmse = statsmodels.tools.eval_measures.rmse(y_test, y_test_pred) # Calculate the Root Mean Squared Error (RMSE) between the actual target values (y_test) and the predicted values (y_test_pred)\n",
    "print(rmse)                                                      # Print the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24492acf-cd1b-4c1a-ba5c-bbfc98a39fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47585825973383%\n"
     ]
    }
   ],
   "source": [
    "mape = metrics.mean_absolute_percentage_error(y_test,y_test_pred) # Calculate the MAPE\n",
    "print(f\"{mape*100}%\")                                             # Print the value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
